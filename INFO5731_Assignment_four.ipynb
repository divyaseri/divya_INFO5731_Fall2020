{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "INFO5731_Assignment_four.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/divyaseri/divya_INFO5731_Fall2020/blob/master/INFO5731_Assignment_four.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "USSdXHuqnwv9"
      },
      "source": [
        "# **INFO5731 Assignment Four**\n",
        "\n",
        "In this assignment, you are required to conduct topic modeling, sentiment analysis, and regression analysis."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YWxodXh5n4xF"
      },
      "source": [
        "# **Question 1: Topic Modeling**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TenBkDJ5n95k"
      },
      "source": [
        "(30 points). This question is designed to help you understand topic modeling better as well as how to visualize topic modeling results, aims to collect the human meanings of documents. Based on the yelp review data (only the review text will be used for this question), which can be download from Dropbox: https://www.dropbox.com/s/59hsrk56sfwh9u2/Assignment%20four%20data%20Yelp%20%28question%201%20and%202%29.zip?dl=0, **select two models** and write a python program to **identify the top 20 topics (with 15 words for each topic) in the dataset**. Before answering this question, please review the materials in lesson 8, as well as the introduction of these models by the links provided.\n",
        "\n",
        "(1)   Labeled LDA (LLDA): https://github.com/JoeZJH/Labeled-LDA-Python\n",
        "\n",
        "(2)   Biterm Topic Model (BTM): https://github.com/markoarnauto/biterm\n",
        "\n",
        "(3)   HMM-LDA: https://github.com/dongwookim-ml/python-topic-model\n",
        "\n",
        "(4)   SupervisedLDA: https://github.com/dongwookim-ml/python-topic-model/tree/master/notebook\n",
        "\n",
        "(5)   Relational Topic Model: https://github.com/dongwookim-ml/python-topic-model/tree/master/notebook\n",
        "\n",
        "(6)   LDA2VEC: https://github.com/cemoody/lda2vec\n",
        "\n",
        "(7)   BERTopic: https://github.com/MaartenGr/BERTopic\n",
        "\n",
        "(8)   LDA+BERT Topic Modeling: https://www.kaggle.com/dskswu/topic-modeling-bert-lda\n",
        "\n",
        "(9)   Clustering for Topic models: (paper: https://arxiv.org/abs/2004.14914), (code: https://github.com/adalmia96/Cluster-Analysis)\n",
        "\n",
        "\n",
        "**The following information should be reported:**\n",
        "\n",
        "(1) Top 20 clusters for topic modeling.\n",
        "\n",
        "(2) Summarize and describe the topic for each cluster. \n",
        "\n",
        "(3) Visualize the topic modeling reasults by using pyLDAVis: https://www.machinelearningplus.com/nlp/topic-modeling-visualization-how-to-present-results-lda-models/#14.-pyLDAVis\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k9h1d-HF9yaZ"
      },
      "source": [
        "from zipfile import ZipFile \n",
        "file_name = '/content/Assignment four data Yelp (question 1 and 2).zip'\n",
        "with ZipFile(file_name, 'r') as zip:  \n",
        "    zip.extractall() "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "id": "tRFePSXt4R_B",
        "outputId": "bb04ce42-5acc-400f-e4ba-c2c852caf259"
      },
      "source": [
        "import os,json\n",
        "import pandas as pd\n",
        "arr = os.listdir('/content/Assignment four data Yelp (question 1 and 2)')\n",
        "reviews = []\n",
        "ratings = []\n",
        "for file in arr:\n",
        "  with open('/content/Assignment four data Yelp (question 1 and 2)/'+file,encoding = \"utf-8\") as i:\n",
        "    data = json.load(i)\n",
        "    for j in data:\n",
        "      reviews.append(j['text'])\n",
        "      ratings.append(j['stars']) \n",
        "input_df = pd.DataFrame(reviews, columns=[\"review\"])\n",
        "input_df[\"ratings\"]=ratings\n",
        "input_df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>ratings</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Exceptional customer service by your service d...</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>I decided to check out downtown Pittsburgh on ...</td>\n",
              "      <td>3.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Just got back home form here and couldn't wait...</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Came here for lunch with a friend last Saturda...</td>\n",
              "      <td>5.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Good food but terrible service.  have been her...</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              review  ratings\n",
              "0  Exceptional customer service by your service d...      5.0\n",
              "1  I decided to check out downtown Pittsburgh on ...      3.0\n",
              "2  Just got back home form here and couldn't wait...      5.0\n",
              "3  Came here for lunch with a friend last Saturda...      5.0\n",
              "4  Good food but terrible service.  have been her...      2.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "id": "IaTxN55o4SCe",
        "outputId": "2392ee86-d153-4b9b-c5a5-ab4c84feddd7"
      },
      "source": [
        "# Data Cleaning\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize  \n",
        "import pandas as pd\n",
        "from textblob import Word\n",
        "import re\n",
        "import nltk\n",
        "\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "stop_words=stopwords.words(\"english\")\n",
        "\n",
        "\n",
        "input_df['cleaned review'] = input_df['review'].str.replace(r\"\\W\", \" \").str.strip()\n",
        "input_df['cleaned review'] = input_df['cleaned review'].str.replace(r'\\d+',\"\") \n",
        "input_df['cleaned review'] = input_df['cleaned review'].apply(lambda x: \" \".join(x.lower() for x in x.split())) \n",
        "input_df['cleaned review'] = input_df['cleaned review'].apply(lambda x: \" \".join(x for x in x.split() if x not in stop_words))\n",
        "input_df.head() "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>ratings</th>\n",
              "      <th>cleaned review</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Exceptional customer service by your service d...</td>\n",
              "      <td>5.0</td>\n",
              "      <td>exceptional customer service service departmen...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>I decided to check out downtown Pittsburgh on ...</td>\n",
              "      <td>3.0</td>\n",
              "      <td>decided check downtown pittsburgh trip family ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Just got back home form here and couldn't wait...</td>\n",
              "      <td>5.0</td>\n",
              "      <td>got back home form wait yelp place came group ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Came here for lunch with a friend last Saturda...</td>\n",
              "      <td>5.0</td>\n",
              "      <td>came lunch friend last saturday waitress promp...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Good food but terrible service.  have been her...</td>\n",
              "      <td>2.0</td>\n",
              "      <td>good food terrible service twice times disappo...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              review  ...                                     cleaned review\n",
              "0  Exceptional customer service by your service d...  ...  exceptional customer service service departmen...\n",
              "1  I decided to check out downtown Pittsburgh on ...  ...  decided check downtown pittsburgh trip family ...\n",
              "2  Just got back home form here and couldn't wait...  ...  got back home form wait yelp place came group ...\n",
              "3  Came here for lunch with a friend last Saturda...  ...  came lunch friend last saturday waitress promp...\n",
              "4  Good food but terrible service.  have been her...  ...  good food terrible service twice times disappo...\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hwDLxcpo8IsJ"
      },
      "source": [
        "#Supervised LDA\n",
        "import os\n",
        "import logging\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from ptm import slda_gibbs\n",
        "from ptm import lda_gibbs\n",
        "from nltk_corpus import get_ids_cnt\n",
        "from utils import convert_cnt_to_list, get_top_words"
      ],
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eZr02u5c8Ive"
      },
      "source": [
        "%matplotlib inline  "
      ],
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ovx1Yh1NDgL5"
      },
      "source": [
        "logger = logging.getLogger('GibbsSupervisedLDA')\n",
        "logger.propagate = False"
      ],
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YRBakuMFDueU",
        "outputId": "782188c3-b353-4349-e701-cc14f4652be0"
      },
      "source": [
        "import nltk\n",
        "nltk.download('words')"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Package words is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ln7tVs_DkfD",
        "outputId": "950b29c7-c7ff-4980-c489-1abc95c5bdb4"
      },
      "source": [
        "# Reading and Tokenizing the dataset\n",
        "\n",
        "voca, word_ids, word_cnt = get_ids_cnt(reviews)\n",
        "corpus = convert_cnt_to_list(word_ids, word_cnt)\n",
        "\n",
        "n_doc = len(corpus)\n",
        "n_voca = voca.size\n",
        "print('Number of Documents:', n_doc, '\\nNumber of Vocabulary:', n_voca)"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of Documents: 500000 \n",
            "Number of Vocabulary: 33741\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CzOLG2ZVD75O",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 236
        },
        "outputId": "bd5fb4a9-8924-4fb0-f31a-dd82d55feb41"
      },
      "source": [
        "# Infering topics with Supervised LDA\n",
        "\n",
        "n_topic = 20\n",
        "r_var = 0.01\n",
        "\n",
        "model = GibbsSupervisedLDA(n_doc, n_voca, n_topic, sigma=r_var)\n",
        "model.fit(corpus, ratings)\n",
        "\n",
        "# Displaying top 15 words from the 20 clusters\n",
        "\n",
        "for ti in model.eta.argsort():\n",
        "    top_words = get_top_words(model.TW, voca, ti, n_words=15)\n",
        "    print('Topic', ti ,':', ','.join(top_words), '\\nEta:', model.eta[ti], '\\n')"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-96-5bd7cdbc5a93>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mr_var\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.01\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGibbsSupervisedLDA\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_doc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_voca\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_topic\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msigma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mr_var\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mratings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'GibbsSupervisedLDA' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AfpMRCrRwN6Z"
      },
      "source": [
        "# **Question 2: Yelp Review Sentiment Analysis**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1dCQEbDawWCw"
      },
      "source": [
        "(30 points). Sentiment analysis also known as opinion mining is a sub field within Natural Language Processing (NLP) that builds machine learning algorithms to classify a text according to the sentimental polarities of opinions it contains, e.g., positive, negative, neutral. The purpose of this question is to develop a machine learning classifier for sentiment analysis. Based on the dataset from assignment three, write a python program to implement a sentiment classifier and evaluate its performance. Notice: **80% data for training and 20% data for testing**.\n",
        "\n",
        "The data can be download from Dropbox: https://www.dropbox.com/s/59hsrk56sfwh9u2/Assignment%20four%20data%20Yelp%20%28question%201%20and%202%29.zip?dl=0 \n",
        "\n",
        "The data was saved in json format, here is an example of the data (for this task, you only need to use the star rating and the review text fields):\n",
        "\n",
        "{\n",
        "    // string, 22 character unique review id\n",
        "    \"review_id\": \"zdSx_SD6obEhz9VrW9uAWA\",\n",
        "\n",
        "    // string, 22 character unique user id, maps to the user in user.json\n",
        "    \"user_id\": \"Ha3iJu77CxlrFm-vQRs_8g\",\n",
        "\n",
        "    // string, 22 character business id, maps to business in business.json\n",
        "    \"business_id\": \"tnhfDv5Il8EaGSXZGiuQGg\",\n",
        "\n",
        "    // integer, star rating\n",
        "    \"stars\": 4,\n",
        "\n",
        "    // string, date formatted YYYY-MM-DD\n",
        "    \"date\": \"2016-03-09\",\n",
        "\n",
        "    // string, the review itself\n",
        "    \"text\": \"Great place to hang out after work: the prices are decent, and the ambience is fun. It's a bit loud, but very lively. The staff is friendly, and the food is good. They have a good selection of drinks.\",\n",
        "\n",
        "    // integer, number of useful votes received\n",
        "    \"useful\": 0,\n",
        "\n",
        "    // integer, number of funny votes received\n",
        "    \"funny\": 0,\n",
        "\n",
        "    // integer, number of cool votes received\n",
        "    \"cool\": 0\n",
        "}\n",
        "\n",
        "The sentiment of can be accessed based on the star rating, if no star information avaliable for a record, just remove that record. Detail star and sentiment level can be matched blew:\n",
        "\n",
        "Very positive = 5 stars\n",
        "\n",
        "Positive = 4 stars\n",
        "\n",
        "Neutral = 3 stars\n",
        "\n",
        "Negative = 2 stars\n",
        "\n",
        "Very negative = 1 star\n",
        "\n",
        "Here is code for yelp data preprocessing: https://github.com/Yelp/dataset-examples. \n",
        "\n",
        "Answer the following questions:\n",
        "\n",
        "(1) Features used for sentiment classification and explain why you select these features (tf-idf, sentiment lexicon, word2vec, etc). Considering achieve the best performance as you can. \n",
        "\n",
        "(2) Select two of the supervised learning algorithm from scikit-learn library: https://scikit-learn.org/stable/supervised_learning.html#supervised-learning, to build a sentiment classifier respectively. \n",
        "\n",
        "(3) Compare the performance over accuracy, precision, recall, and F1 score for the two algorithms you selected. Here is the reference of how to calculate these metrics: https://towardsdatascience.com/accuracy-precision-recall-or-f1-331fb37c5cb9. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vATjQNTY8buA"
      },
      "source": [
        "# Write your code here\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E5mmYIfN8eYV"
      },
      "source": [
        "# **Question 3: House price prediction**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hsi2y4z88ngX"
      },
      "source": [
        "(40 points). You are required to build a **regression** model to predict the house price with 79 explanatory variables describing (almost) every aspect of residential homes. The purpose of this question is to practice regression analysis, an supervised learning model. The training data, testing data, and data description files can be download from Dropbox: https://www.dropbox.com/s/52j9hpxppfo921o/assignment4-question3-data.zip?dl=0. Here is an axample for the implementation: https://towardsdatascience.com/linear-regression-in-python-predict-the-bay-areas-home-price-5c91c8378878. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XfvMKJjIXS5G"
      },
      "source": [
        "# Write your code here"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
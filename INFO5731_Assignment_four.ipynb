{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "INFO5731_Assignment_four.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/divyaseri/divya_INFO5731_Fall2020/blob/master/INFO5731_Assignment_four.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "USSdXHuqnwv9"
      },
      "source": [
        "# **INFO5731 Assignment Four**\n",
        "\n",
        "In this assignment, you are required to conduct topic modeling, sentiment analysis, and regression analysis."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YWxodXh5n4xF"
      },
      "source": [
        "# **Question 1: Topic Modeling**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TenBkDJ5n95k"
      },
      "source": [
        "(30 points). This question is designed to help you understand topic modeling better as well as how to visualize topic modeling results, aims to collect the human meanings of documents. Based on the yelp review data (only the review text will be used for this question), which can be download from Dropbox: https://www.dropbox.com/s/59hsrk56sfwh9u2/Assignment%20four%20data%20Yelp%20%28question%201%20and%202%29.zip?dl=0, **select two models** and write a python program to **identify the top 20 topics (with 15 words for each topic) in the dataset**. Before answering this question, please review the materials in lesson 8, as well as the introduction of these models by the links provided.\n",
        "\n",
        "(1)   Labeled LDA (LLDA): https://github.com/JoeZJH/Labeled-LDA-Python\n",
        "\n",
        "(2)   Biterm Topic Model (BTM): https://github.com/markoarnauto/biterm\n",
        "\n",
        "(3)   HMM-LDA: https://github.com/dongwookim-ml/python-topic-model\n",
        "\n",
        "(4)   SupervisedLDA: https://github.com/dongwookim-ml/python-topic-model/tree/master/notebook\n",
        "\n",
        "(5)   Relational Topic Model: https://github.com/dongwookim-ml/python-topic-model/tree/master/notebook\n",
        "\n",
        "(6)   LDA2VEC: https://github.com/cemoody/lda2vec\n",
        "\n",
        "(7)   BERTopic: https://github.com/MaartenGr/BERTopic\n",
        "\n",
        "(8)   LDA+BERT Topic Modeling: https://www.kaggle.com/dskswu/topic-modeling-bert-lda\n",
        "\n",
        "(9)   Clustering for Topic models: (paper: https://arxiv.org/abs/2004.14914), (code: https://github.com/adalmia96/Cluster-Analysis)\n",
        "\n",
        "\n",
        "**The following information should be reported:**\n",
        "\n",
        "(1) Top 20 clusters for topic modeling.\n",
        "\n",
        "(2) Summarize and describe the topic for each cluster. \n",
        "\n",
        "(3) Visualize the topic modeling reasults by using pyLDAVis: https://www.machinelearningplus.com/nlp/topic-modeling-visualization-how-to-present-results-lda-models/#14.-pyLDAVis\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PuFPKhC0m1fd"
      },
      "source": [
        "import pickle\n",
        "import logging\n",
        " \n",
        "import numpy as np\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "4F_aD1tE6q42",
        "outputId": "5cfba386-ef95-4f3f-bd6d-0cc91c1dea5c"
      },
      "source": [
        "import os\n",
        "os.getcwd()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Aj9A0iqC6zex"
      },
      "source": [
        "from zipfile import ZipFile \n",
        "workingDirecoty = '/content/Assignment four data Yelp (question 1 and 2).zip'\n",
        "with ZipFile(workingDirecoty, 'r') as item:  \n",
        "    item.extractall() "
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "abAB9mJ98gEI"
      },
      "source": [
        "import pandas as pd\n",
        "import glob\n",
        "import json\n",
        "filename = glob.glob(\"/content/Assignment four data Yelp (question 1 and 2)/*.json\")\n",
        "text = list()\n",
        "stars = list()\n",
        "date = list()\n",
        "for file in filename:\n",
        "  with open(file,encoding = \"utf-8\") as i:\n",
        "    json_data = json.load(i)\n",
        "    for data in json_data:\n",
        "      text.append(data['text'])\n",
        "      stars.append(data['stars'])\n",
        "      date.append(data['date'])"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 355
        },
        "id": "PB-AgzAB8s0o",
        "outputId": "ff693951-2463-4643-ebd1-78255c01926e"
      },
      "source": [
        "required_df = pd.DataFrame(text_field,columns = [\"Review\"])\n",
        "required_df[\"Rating\"] = stars\n",
        "required_df[\"Date\"] = date_value\n",
        "required_df.head(10)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Review</th>\n",
              "      <th>Rating</th>\n",
              "      <th>Date</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Awesome service and fantastic food, the wait s...</td>\n",
              "      <td>5.0</td>\n",
              "      <td>2018-03-01 17:25:51</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Seemed pretty pricey to me for what you got......</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2012-01-21 17:44:58</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>We TRIED to go to the buffet on Tuesday eve fo...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2014-10-06 01:56:38</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Came here for lunch on my 20th birthday and th...</td>\n",
              "      <td>5.0</td>\n",
              "      <td>2017-04-26 07:05:13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Amazing treats - I love their cinnamon roll, c...</td>\n",
              "      <td>5.0</td>\n",
              "      <td>2018-09-10 23:00:12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Me and my family went to TasteBuds tonight..I ...</td>\n",
              "      <td>4.0</td>\n",
              "      <td>2015-05-19 06:32:17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Stay away from this train wreck of a hospital ...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2014-10-06 23:19:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>I have now had two amazing meals here and can'...</td>\n",
              "      <td>5.0</td>\n",
              "      <td>2012-01-20 21:04:38</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>My classmates and I go here because we go to c...</td>\n",
              "      <td>4.0</td>\n",
              "      <td>2015-09-17 01:46:28</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Really good service. They helped us pick out f...</td>\n",
              "      <td>5.0</td>\n",
              "      <td>2018-07-14 19:17:05</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              Review  ...                 Date\n",
              "0  Awesome service and fantastic food, the wait s...  ...  2018-03-01 17:25:51\n",
              "1  Seemed pretty pricey to me for what you got......  ...  2012-01-21 17:44:58\n",
              "2  We TRIED to go to the buffet on Tuesday eve fo...  ...  2014-10-06 01:56:38\n",
              "3  Came here for lunch on my 20th birthday and th...  ...  2017-04-26 07:05:13\n",
              "4  Amazing treats - I love their cinnamon roll, c...  ...  2018-09-10 23:00:12\n",
              "5  Me and my family went to TasteBuds tonight..I ...  ...  2015-05-19 06:32:17\n",
              "6  Stay away from this train wreck of a hospital ...  ...  2014-10-06 23:19:01\n",
              "7  I have now had two amazing meals here and can'...  ...  2012-01-20 21:04:38\n",
              "8  My classmates and I go here because we go to c...  ...  2015-09-17 01:46:28\n",
              "9  Really good service. They helped us pick out f...  ...  2018-07-14 19:17:05\n",
              "\n",
              "[10 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zpFti3ct85h1",
        "outputId": "33fe8c5a-9eeb-49ca-afd2-795119531029"
      },
      "source": [
        "required_df[\"cleaned_data\"] = required_df[\"Review\"].apply(lambda x : x.lower())\n",
        "import string\n",
        "required_df[\"cleaned_data\"] = required_df[\"cleaned_data\"].apply(lambda x : ''.join([i for i in x if i not in string.punctuation]))\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "list_of_words = set(stopwords.words('english'))\n",
        "required_df[\"cleaned_data\"] = required_df[\"cleaned_data\"].apply(lambda x: ' '.join([i for i in x.split() if i not in list_of_words]))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "72kpTI_s9Is1",
        "outputId": "6cfd56de-b661-40b5-87b2-f867aa4ecb4c"
      },
      "source": [
        "!pip install textblob"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: textblob in /usr/local/lib/python3.6/dist-packages (0.15.3)\n",
            "Requirement already satisfied: nltk>=3.1 in /usr/local/lib/python3.6/dist-packages (from textblob) (3.2.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from nltk>=3.1->textblob) (1.15.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Wyhy-QP9A_k"
      },
      "source": [
        "frequent_words = list(pd.Series(' '.join(required_df['cleaned_data']).split()).value_counts()[:15].index)\n",
        "rare_words = list(pd.Series(' '.join(required_df['cleaned_data']).split()).value_counts()[-15:].index)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F1aPKbAu9Mzp"
      },
      "source": [
        "from textblob import TextBlob"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yn7doZzp9eSe"
      },
      "source": [
        "required_df[\"cleaned_data\"] = required_df[\"cleaned_data\"].apply(lambda x: ' '.join([i for i in x.split() if i not in frequent_words]))\n",
        "required_df[\"cleaned_data\"] = required_df[\"cleaned_data\"].apply(lambda x: ' '.join([i for i in x.split() if i not in rare_words]))"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zTILB1Kf9jRY",
        "outputId": "7ce6f859-b410-49f1-ff56-b094c480eec1"
      },
      "source": [
        "from nltk.stem import PorterStemmer \n",
        "from nltk.tokenize import word_tokenize \n",
        "import textblob\n",
        "ps = PorterStemmer() \n",
        "nltk.download('wordnet')\n",
        "nltk.download('punkt')"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 355
        },
        "id": "yOfDF6rq9pSj",
        "outputId": "c60ad1e6-9681-41e2-f335-0c78ab9916e1"
      },
      "source": [
        "required_df[\"cleaned_data\"] = required_df[\"cleaned_data\"].apply(lambda x: ' '.join(word_tokenize(str(x))))\n",
        "required_df.head(10)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Review</th>\n",
              "      <th>Rating</th>\n",
              "      <th>Date</th>\n",
              "      <th>cleaned_data</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Awesome service and fantastic food, the wait s...</td>\n",
              "      <td>5.0</td>\n",
              "      <td>2018-03-01 17:25:51</td>\n",
              "      <td>awesome fantastic wait staff friendly accommod...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Seemed pretty pricey to me for what you got......</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2012-01-21 17:44:58</td>\n",
              "      <td>seemed pretty pricey gotburgers tasted pretty ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>We TRIED to go to the buffet on Tuesday eve fo...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2014-10-06 01:56:38</td>\n",
              "      <td>tried buffet tuesday eve dinner found closed m...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Came here for lunch on my 20th birthday and th...</td>\n",
              "      <td>5.0</td>\n",
              "      <td>2017-04-26 07:05:13</td>\n",
              "      <td>came lunch 20th birthday gave free dessert sig...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Amazing treats - I love their cinnamon roll, c...</td>\n",
              "      <td>5.0</td>\n",
              "      <td>2018-09-10 23:00:12</td>\n",
              "      <td>amazing treats love cinnamon roll cupcakes ice...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Me and my family went to TasteBuds tonight..I ...</td>\n",
              "      <td>4.0</td>\n",
              "      <td>2015-05-19 06:32:17</td>\n",
              "      <td>family went tastebuds tonighti love begin went...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Stay away from this train wreck of a hospital ...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2014-10-06 23:19:01</td>\n",
              "      <td>stay away train wreck hospital er unprofession...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>I have now had two amazing meals here and can'...</td>\n",
              "      <td>5.0</td>\n",
              "      <td>2012-01-20 21:04:38</td>\n",
              "      <td>two amazing meals cant wait return steaks lobs...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>My classmates and I go here because we go to c...</td>\n",
              "      <td>4.0</td>\n",
              "      <td>2015-09-17 01:46:28</td>\n",
              "      <td>classmates cpcc walking distance classes alway...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Really good service. They helped us pick out f...</td>\n",
              "      <td>5.0</td>\n",
              "      <td>2018-07-14 19:17:05</td>\n",
              "      <td>helped pick frames whole family patient billed...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              Review  ...                                       cleaned_data\n",
              "0  Awesome service and fantastic food, the wait s...  ...  awesome fantastic wait staff friendly accommod...\n",
              "1  Seemed pretty pricey to me for what you got......  ...  seemed pretty pricey gotburgers tasted pretty ...\n",
              "2  We TRIED to go to the buffet on Tuesday eve fo...  ...  tried buffet tuesday eve dinner found closed m...\n",
              "3  Came here for lunch on my 20th birthday and th...  ...  came lunch 20th birthday gave free dessert sig...\n",
              "4  Amazing treats - I love their cinnamon roll, c...  ...  amazing treats love cinnamon roll cupcakes ice...\n",
              "5  Me and my family went to TasteBuds tonight..I ...  ...  family went tastebuds tonighti love begin went...\n",
              "6  Stay away from this train wreck of a hospital ...  ...  stay away train wreck hospital er unprofession...\n",
              "7  I have now had two amazing meals here and can'...  ...  two amazing meals cant wait return steaks lobs...\n",
              "8  My classmates and I go here because we go to c...  ...  classmates cpcc walking distance classes alway...\n",
              "9  Really good service. They helped us pick out f...  ...  helped pick frames whole family patient billed...\n",
              "\n",
              "[10 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q1VHbraU9x_3"
      },
      "source": [
        "from gensim import corpora, models\n",
        "reviews_data = required_df[\"cleaned_data\"].head(10000).values\n",
        "reviews = [i.split() for i in reviews_data]\n",
        "\n",
        "dictionary_LLDA = corpora.Dictionary(reviews)\n",
        "dictionary_LLDA.filter_extremes(no_below=3)\n",
        "corpus = [dictionary_LLDA.doc2bow(list_of_tokens) for list_of_tokens in reviews]\n",
        "\n",
        "num_topics = 20\n",
        "%time lda_model = models.LdaModel(corpus, num_topics=num_topics, \\\n",
        "                                  id2word=dictionary_LLDA, \\\n",
        "                                  passes=4, alpha=[0.01]*num_topics, \\\n",
        "                                  eta=[0.01]*len(dictionary_LLDA.keys()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k9h1d-HF9yaZ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AfpMRCrRwN6Z"
      },
      "source": [
        "# **Question 2: Yelp Review Sentiment Analysis**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1dCQEbDawWCw"
      },
      "source": [
        "(30 points). Sentiment analysis also known as opinion mining is a sub field within Natural Language Processing (NLP) that builds machine learning algorithms to classify a text according to the sentimental polarities of opinions it contains, e.g., positive, negative, neutral. The purpose of this question is to develop a machine learning classifier for sentiment analysis. Based on the dataset from assignment three, write a python program to implement a sentiment classifier and evaluate its performance. Notice: **80% data for training and 20% data for testing**.\n",
        "\n",
        "The data can be download from Dropbox: https://www.dropbox.com/s/59hsrk56sfwh9u2/Assignment%20four%20data%20Yelp%20%28question%201%20and%202%29.zip?dl=0 \n",
        "\n",
        "The data was saved in json format, here is an example of the data (for this task, you only need to use the star rating and the review text fields):\n",
        "\n",
        "{\n",
        "    // string, 22 character unique review id\n",
        "    \"review_id\": \"zdSx_SD6obEhz9VrW9uAWA\",\n",
        "\n",
        "    // string, 22 character unique user id, maps to the user in user.json\n",
        "    \"user_id\": \"Ha3iJu77CxlrFm-vQRs_8g\",\n",
        "\n",
        "    // string, 22 character business id, maps to business in business.json\n",
        "    \"business_id\": \"tnhfDv5Il8EaGSXZGiuQGg\",\n",
        "\n",
        "    // integer, star rating\n",
        "    \"stars\": 4,\n",
        "\n",
        "    // string, date formatted YYYY-MM-DD\n",
        "    \"date\": \"2016-03-09\",\n",
        "\n",
        "    // string, the review itself\n",
        "    \"text\": \"Great place to hang out after work: the prices are decent, and the ambience is fun. It's a bit loud, but very lively. The staff is friendly, and the food is good. They have a good selection of drinks.\",\n",
        "\n",
        "    // integer, number of useful votes received\n",
        "    \"useful\": 0,\n",
        "\n",
        "    // integer, number of funny votes received\n",
        "    \"funny\": 0,\n",
        "\n",
        "    // integer, number of cool votes received\n",
        "    \"cool\": 0\n",
        "}\n",
        "\n",
        "The sentiment of can be accessed based on the star rating, if no star information avaliable for a record, just remove that record. Detail star and sentiment level can be matched blew:\n",
        "\n",
        "Very positive = 5 stars\n",
        "\n",
        "Positive = 4 stars\n",
        "\n",
        "Neutral = 3 stars\n",
        "\n",
        "Negative = 2 stars\n",
        "\n",
        "Very negative = 1 star\n",
        "\n",
        "Here is code for yelp data preprocessing: https://github.com/Yelp/dataset-examples. \n",
        "\n",
        "Answer the following questions:\n",
        "\n",
        "(1) Features used for sentiment classification and explain why you select these features (tf-idf, sentiment lexicon, word2vec, etc). Considering achieve the best performance as you can. \n",
        "\n",
        "(2) Select two of the supervised learning algorithm from scikit-learn library: https://scikit-learn.org/stable/supervised_learning.html#supervised-learning, to build a sentiment classifier respectively. \n",
        "\n",
        "(3) Compare the performance over accuracy, precision, recall, and F1 score for the two algorithms you selected. Here is the reference of how to calculate these metrics: https://towardsdatascience.com/accuracy-precision-recall-or-f1-331fb37c5cb9. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vATjQNTY8buA"
      },
      "source": [
        "# Write your code here\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E5mmYIfN8eYV"
      },
      "source": [
        "# **Question 3: House price prediction**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hsi2y4z88ngX"
      },
      "source": [
        "(40 points). You are required to build a **regression** model to predict the house price with 79 explanatory variables describing (almost) every aspect of residential homes. The purpose of this question is to practice regression analysis, an supervised learning model. The training data, testing data, and data description files can be download from Dropbox: https://www.dropbox.com/s/52j9hpxppfo921o/assignment4-question3-data.zip?dl=0. Here is an axample for the implementation: https://towardsdatascience.com/linear-regression-in-python-predict-the-bay-areas-home-price-5c91c8378878. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XfvMKJjIXS5G"
      },
      "source": [
        "# Write your code here"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
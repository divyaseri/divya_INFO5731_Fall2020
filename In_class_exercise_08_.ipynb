{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "In_class_exercise_08 .ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/divyaseri/divya_INFO5731_Fall2020/blob/master/In_class_exercise_08_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9KMCMaer19Iu"
      },
      "source": [
        "# **The eighth in-class-exercise (20 points in total, 10/29/2020)**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "85-wmb_J19Iz"
      },
      "source": [
        "The data for this exercise is from the dataset you created from assignment three. Please perform answer the following questions based on your data:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UIj3Pskf19I2"
      },
      "source": [
        "## (1) (10 points) Write a python program to extract the sentiment related terms from the corpus. You may use python package such as polyglot or external lexicon resources in the question. Rank the sentiment related terms by frequency."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CzX5wvZG19I5",
        "outputId": "0200ecd0-f8ac-4784-cc76-9f33a76e5973",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install polyglot "
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting polyglot\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e7/98/e24e2489114c5112b083714277204d92d372f5bbe00d5507acf40370edb9/polyglot-16.7.4.tar.gz (126kB)\n",
            "\r\u001b[K     |██▋                             | 10kB 16.5MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 20kB 1.6MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 30kB 1.8MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 40kB 2.1MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 51kB 2.0MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 61kB 2.2MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 71kB 2.4MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 81kB 2.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 92kB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 102kB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 112kB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 122kB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 133kB 2.7MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: polyglot\n",
            "  Building wheel for polyglot (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for polyglot: filename=polyglot-16.7.4-py2.py3-none-any.whl size=52559 sha256=3381f52cc757ed8e22f8adbdf027766409ca1b2e7fddd0699f9b0b861df183f6\n",
            "  Stored in directory: /root/.cache/pip/wheels/5e/91/ef/f1369fdc1203b0a9347d4b24f149b83a305f39ab047986d9da\n",
            "Successfully built polyglot\n",
            "Installing collected packages: polyglot\n",
            "Successfully installed polyglot-16.7.4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aTq7qpXNqeS7",
        "outputId": "230a5909-e803-4aec-ce7a-f865ce03fe35",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install Morfessor"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting Morfessor\n",
            "  Downloading https://files.pythonhosted.org/packages/39/e6/7afea30be2ee4d29ce9de0fa53acbb033163615f849515c0b1956ad074ee/Morfessor-2.0.6-py3-none-any.whl\n",
            "Installing collected packages: Morfessor\n",
            "Successfully installed Morfessor-2.0.6\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uA1zF9J4qe9_",
        "outputId": "2c98fd63-7d9f-4b88-c07d-bd5693e5119d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install pyicu"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pyicu\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5a/99/c48c816095208bf3f4936ff67e571621fbddef461303a35a076f234e31f6/PyICU-2.5.tar.gz (225kB)\n",
            "\r\u001b[K     |█▌                              | 10kB 16.9MB/s eta 0:00:01\r\u001b[K     |███                             | 20kB 1.7MB/s eta 0:00:01\r\u001b[K     |████▍                           | 30kB 2.0MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 40kB 2.3MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 51kB 2.0MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 61kB 2.2MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 71kB 2.4MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 81kB 2.6MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 92kB 2.9MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 102kB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████████                | 112kB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 122kB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████████████▉             | 133kB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 143kB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 153kB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 163kB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 174kB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 184kB 2.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 194kB 2.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 204kB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 215kB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 225kB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 235kB 2.7MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyicu\n",
            "  Building wheel for pyicu (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyicu: filename=PyICU-2.5-cp36-cp36m-linux_x86_64.whl size=1252556 sha256=7673fda7acc595cc3575e45fac944d67c1373fbd802b38a7357b4d56cab4d306\n",
            "  Stored in directory: /root/.cache/pip/wheels/07/3a/28/09f90c38785945ddf9af61b7add1aa62a740f40e259626ef3a\n",
            "Successfully built pyicu\n",
            "Installing collected packages: pyicu\n",
            "Successfully installed pyicu-2.5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M1SB8IbIqfMq",
        "outputId": "2158433b-e3df-4793-b6a8-08da43a644c8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install pycld2"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pycld2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/21/d2/8b0def84a53c88d0eb27c67b05269fbd16ad68df8c78849e7b5d65e6aec3/pycld2-0.41.tar.gz (41.4MB)\n",
            "\u001b[K     |████████████████████████████████| 41.4MB 108kB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pycld2\n",
            "  Building wheel for pycld2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pycld2: filename=pycld2-0.41-cp36-cp36m-linux_x86_64.whl size=9833595 sha256=4ab6ff2d4d6a3f3c0eaa457dce1795d75b3752b27cfcd971df6abe0ff4ee2274\n",
            "  Stored in directory: /root/.cache/pip/wheels/c6/8f/e9/08a1a8932a490175bd140206cd86a3dbcfc70498100de11079\n",
            "Successfully built pycld2\n",
            "Installing collected packages: pycld2\n",
            "Successfully installed pycld2-0.41\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HhFMGMTzqzM8",
        "outputId": "d0145038-cac1-4471-b221-1695b9aecdf9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "%%bash\n",
        "polyglot download embeddings2.en pos2.en"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[polyglot_data] Downloading package embeddings2.en to\n",
            "[polyglot_data]     /root/polyglot_data...\n",
            "[polyglot_data] Downloading package pos2.en to /root/polyglot_data...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kPXRa68HrD5R",
        "outputId": "43ef5fa6-65ca-459e-e696-77902370f7e8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "from polyglot.text import Text\n",
        "df=pd.read_csv(\"/content/Review_file.csv\")\n",
        "data=[]\n",
        "\n",
        "# 1.To remove special characters, punctuations and numbers\n",
        "df[\"Review\"] = df[\"Review\"].str.replace(r\"\\W\", \" \").str.strip()\n",
        "df[\"Review\"]= df[\"Review\"].str.replace(r'\\d+',\"\")\n",
        "for a in df[\"Review\"]:   \n",
        "   data.append(a)\n",
        "df['data']=pd.DataFrame(data)\n",
        "blob = df['data'].to_string()\n",
        "text = Text(blob)\n",
        "tags=text.pos_tags\n",
        "#tags\n",
        "sent_word = [x for (x,y) in tags if y not in ('NUM','PUNCT','ADP','AUX','CONJ','DET',\n",
        "                                              'INTJ','NOUN','PART','PRON','PROPN',\n",
        "                                              'SCONJ','SYM','X','VERB','ADV')]\n",
        "sent_word"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Best',\n",
              " 'de',\n",
              " 'early',\n",
              " 'sad',\n",
              " 'good',\n",
              " 'recurring',\n",
              " 'many',\n",
              " 'intense',\n",
              " 'more',\n",
              " 'perfect',\n",
              " 'Amazing',\n",
              " 'magnificent',\n",
              " 'complete',\n",
              " 'worthy',\n",
              " 'Joaquin',\n",
              " 'best',\n",
              " 'few',\n",
              " 'unbelievable',\n",
              " 'high',\n",
              " 'incredible',\n",
              " 'unconvincing',\n",
              " 'best',\n",
              " 'mental',\n",
              " 'short',\n",
              " 'cinematic',\n",
              " 'good',\n",
              " 'sure',\n",
              " 'Creative',\n",
              " 'compelling',\n",
              " 'new',\n",
              " 'Absolute',\n",
              " 'silly',\n",
              " 'Best',\n",
              " 'first',\n",
              " 'Amazing',\n",
              " 'enjoyable',\n",
              " 'Dark',\n",
              " 'entertaining',\n",
              " 'dark',\n",
              " 'perfect',\n",
              " 'best',\n",
              " 'dark',\n",
              " 'understandable',\n",
              " 'interesting',\n",
              " 'real',\n",
              " 'brilliant',\n",
              " 'hyped',\n",
              " 'unique',\n",
              " 'more',\n",
              " 'outstanding',\n",
              " 'strong',\n",
              " 'stunning',\n",
              " 'lite',\n",
              " 'excellent',\n",
              " 'amazing',\n",
              " 'first',\n",
              " 'unconvincing',\n",
              " 'excellent',\n",
              " 'good']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zgt9hKLwsJN9",
        "outputId": "3b3a3aca-2b75-460c-f693-d10a32e51493",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import collections\n",
        "from operator import itemgetter\n",
        "N = 200\n",
        "frequency = collections.Counter(sent_word)\n",
        "top_words = sorted(frequency.items(), key=itemgetter(1), reverse=True)[:N]\n",
        "for i, (word, frequency) in enumerate(top_words, start=1):\n",
        "    print(\"%d %s %d\" % (i, word, frequency))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1 good 3\n",
            "2 best 3\n",
            "3 Best 2\n",
            "4 more 2\n",
            "5 perfect 2\n",
            "6 Amazing 2\n",
            "7 unconvincing 2\n",
            "8 first 2\n",
            "9 dark 2\n",
            "10 excellent 2\n",
            "11 de 1\n",
            "12 early 1\n",
            "13 sad 1\n",
            "14 recurring 1\n",
            "15 many 1\n",
            "16 intense 1\n",
            "17 magnificent 1\n",
            "18 complete 1\n",
            "19 worthy 1\n",
            "20 Joaquin 1\n",
            "21 few 1\n",
            "22 unbelievable 1\n",
            "23 high 1\n",
            "24 incredible 1\n",
            "25 mental 1\n",
            "26 short 1\n",
            "27 cinematic 1\n",
            "28 sure 1\n",
            "29 Creative 1\n",
            "30 compelling 1\n",
            "31 new 1\n",
            "32 Absolute 1\n",
            "33 silly 1\n",
            "34 enjoyable 1\n",
            "35 Dark 1\n",
            "36 entertaining 1\n",
            "37 understandable 1\n",
            "38 interesting 1\n",
            "39 real 1\n",
            "40 brilliant 1\n",
            "41 hyped 1\n",
            "42 unique 1\n",
            "43 outstanding 1\n",
            "44 strong 1\n",
            "45 stunning 1\n",
            "46 lite 1\n",
            "47 amazing 1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IgDkrOSg19JK"
      },
      "source": [
        "## (2) (10 points) Compare the performance of the following tools in sentiment identification: TextBlob (https://textblob.readthedocs.io/en/dev/), VADER (https://github.com/cjhutto/vaderSentiment), TFIDF-based Support Vector Machine (SVM) (Split your data into training and testing data). Take your own annotation as the standard answers. \n",
        "\n",
        "Reference code: https://towardsdatascience.com/fine-grained-sentiment-analysis-in-python-part-1-2697bb111ed4"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PRxVsA4y19JN"
      },
      "source": [
        "# Write your code here\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Your analysis here\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}